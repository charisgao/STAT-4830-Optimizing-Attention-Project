{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "270ee667fb6b42e58084b4949110b31d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0354a5a727f94aa59e4c84a16912fd7f",
              "IPY_MODEL_1300055fd47a4f98b35e89a3d270e3c4",
              "IPY_MODEL_4c7bdd4b5fba4068a8cef4a400214c14"
            ],
            "layout": "IPY_MODEL_7511a81ca67f42f094b5308b81b8bde1"
          }
        },
        "0354a5a727f94aa59e4c84a16912fd7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6618ddf7a8e74f92a0a55454e6ed6ca6",
            "placeholder": "​",
            "style": "IPY_MODEL_43b300ea48904320a7bbaa274aab3972",
            "value": "Map: 100%"
          }
        },
        "1300055fd47a4f98b35e89a3d270e3c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c3a64a305bd4c97aa2c06d9c7a45203",
            "max": 36718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dea4223d5a0b4837a4332a158f0e6690",
            "value": 36718
          }
        },
        "4c7bdd4b5fba4068a8cef4a400214c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5a1b7f3a1fa4b66be2d837c5fadeb94",
            "placeholder": "​",
            "style": "IPY_MODEL_21868b83e1514e46bd064d61bc633646",
            "value": " 36718/36718 [00:07&lt;00:00, 3372.46 examples/s]"
          }
        },
        "7511a81ca67f42f094b5308b81b8bde1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6618ddf7a8e74f92a0a55454e6ed6ca6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43b300ea48904320a7bbaa274aab3972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c3a64a305bd4c97aa2c06d9c7a45203": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dea4223d5a0b4837a4332a158f0e6690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5a1b7f3a1fa4b66be2d837c5fadeb94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21868b83e1514e46bd064d61bc633646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c5d137051b14029a9f8ce605b8822a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65a8a2f723584f5cabdc4ddfe42da465",
              "IPY_MODEL_6a69eef767eb4ccea29bc358582cc061",
              "IPY_MODEL_0f31bb7e1c6b4adea81bfcf517f036b9"
            ],
            "layout": "IPY_MODEL_eb391af1f3b44584b1f84b535bbbc02b"
          }
        },
        "65a8a2f723584f5cabdc4ddfe42da465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c6eaa8738044388aad7bf920bf5a66c",
            "placeholder": "​",
            "style": "IPY_MODEL_35204ba9480f44eca77e7e33262f8d81",
            "value": "Map: 100%"
          }
        },
        "6a69eef767eb4ccea29bc358582cc061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ca4783d8a9d44dc9a975f1010338aee",
            "max": 36718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c1857891a16443498bd2aaed3e644b1",
            "value": 36718
          }
        },
        "0f31bb7e1c6b4adea81bfcf517f036b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1035f7eb697464590597f3223b0fa9c",
            "placeholder": "​",
            "style": "IPY_MODEL_7ab11b24f06440a298b2abd159156828",
            "value": " 36718/36718 [00:01&lt;00:00, 32467.02 examples/s]"
          }
        },
        "eb391af1f3b44584b1f84b535bbbc02b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c6eaa8738044388aad7bf920bf5a66c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35204ba9480f44eca77e7e33262f8d81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ca4783d8a9d44dc9a975f1010338aee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c1857891a16443498bd2aaed3e644b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1035f7eb697464590597f3223b0fa9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ab11b24f06440a298b2abd159156828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CesBezVgonKK",
        "outputId": "b01d1f8e-8cf1-438e-936b-60e8d19baced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# From Hugging Face\n",
        "from transformers import (\n",
        "    PreTrainedModel,\n",
        "    PretrainedConfig,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    AutoTokenizer,\n",
        ")\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "k6pGo1hSpBDq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTKerformerConfig(PretrainedConfig):\n",
        "    model_type = \"gpt-kerformer\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size=50257,\n",
        "        max_position_embeddings=1024,\n",
        "        n_embd=256,\n",
        "        n_layer=4,\n",
        "        n_head=4,\n",
        "        hidden_dropout_prob=0.1,\n",
        "        attention_probs_dropout_prob=0.1,\n",
        "        kerformer_degree=2,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_position_embeddings = max_position_embeddings\n",
        "        self.n_embd = n_embd\n",
        "        self.n_layer = n_layer\n",
        "        self.n_head = n_head\n",
        "        self.hidden_dropout_prob = hidden_dropout_prob\n",
        "        self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
        "        self.kerformer_degree = kerformer_degree"
      ],
      "metadata": {
        "id": "EI3mblAhopsu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------\n",
        "# 2. Implement the Kerformer Attention\n",
        "# -------------------------------------------\n",
        "\n",
        "class KerformerAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embed_dim,\n",
        "        num_heads,\n",
        "        nb_features=64,\n",
        "        dropout=0.1,\n",
        "        causal=True,\n",
        "        degree=2, # polynomial degree\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.nb_features = nb_features\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "\n",
        "        # Q, K, V linear projections\n",
        "        self.query = nn.Linear(embed_dim, embed_dim)\n",
        "        self.key = nn.Linear(embed_dim, embed_dim)\n",
        "        self.value = nn.Linear(embed_dim, embed_dim)\n",
        "        self.out = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "        self.causal = causal\n",
        "        self.degree = degree\n",
        "\n",
        "        # If kernel is purely deterministic, no random features needed\n",
        "        # self.random_features = ...\n",
        "        # self.feature_scaling = ...\n",
        "\n",
        "    def _kernel_projection(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Example polynomial feature map, plus row-wise normalization.\n",
        "        x shape: [batch_size, seq_len, num_heads, head_dim]\n",
        "        \"\"\"\n",
        "        # Simple polynomial expansion: phi(x) = [ 1, sqrt(2)*x, x^2, ... ]\n",
        "        # This is just an example, could do something more sophisticated or trainable parameterization\n",
        "\n",
        "        # shape [B, S, H, D]\n",
        "        # Up to (degree=2): phi(x) = [ x, x^2 ]\n",
        "        x_sq = x * x\n",
        "        # Concatenate: shape => [B, S, H, 2*D]\n",
        "        features = torch.cat([x, x_sq], dim=-1)\n",
        "\n",
        "        # Row-wise normalization for stability:\n",
        "        # sum over the \"feature\" dimension, which is -1\n",
        "        eps = 1e-6\n",
        "        denom = torch.sum(features, dim=-1, keepdim=True) + eps\n",
        "        features = features / denom # normalize row by row\n",
        "\n",
        "        return features\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None):\n",
        "        \"\"\"\n",
        "        hidden_states: (batch_size, seq_len, embed_dim)\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, _ = hidden_states.size()\n",
        "\n",
        "        # Project Q, K, V\n",
        "        q = self.query(hidden_states)  # [B, S, E]\n",
        "        k = self.key(hidden_states)\n",
        "        v = self.value(hidden_states)\n",
        "\n",
        "        # Reshape to multiple heads\n",
        "        q = q.view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "        k = k.view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "        v = v.view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Kernel feature mapping (deterministic polynomial example)\n",
        "        q_features = self._kernel_projection(q)  # [B, S, H, ~2*D or something]\n",
        "        k_features = self._kernel_projection(k)  # [B, S, H, ~2*D]\n",
        "\n",
        "        # k_features_v: shape [B, H, feature_dim, head_dim]\n",
        "        # we have to re-check dimension sizes if we used 2*D features, etc.:\n",
        "        # For example:\n",
        "        # q_features => [B, S, H, 2D]\n",
        "        # v          => [B, S, H,   D]\n",
        "        # => we want to do an einsum that yields [B, H, 2D, D]\n",
        "        k_features_v = torch.einsum(\"bshf,bshd->bhfd\", k_features, v)\n",
        "\n",
        "        # Then approximate attention output:\n",
        "        attn_out = torch.einsum(\"bshf,bhfd->bshd\", q_features, k_features_v)\n",
        "\n",
        "        # (Optional) scaling\n",
        "        attn_out = attn_out / math.sqrt(self.head_dim)\n",
        "\n",
        "        # Merge heads\n",
        "        attn_out = attn_out.permute(0, 2, 1, 3).contiguous()  # [B, H, S, D]\n",
        "        attn_out = attn_out.view(batch_size, seq_len, self.embed_dim)\n",
        "\n",
        "        # Final linear + dropout\n",
        "        attn_out = self.out(attn_out)\n",
        "        attn_out = self.dropout(attn_out)\n",
        "\n",
        "        return attn_out"
      ],
      "metadata": {
        "id": "kKKx1meWosaV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------\n",
        "# 3. Define a GPT-Kerformer Block\n",
        "# -------------------------------------------\n",
        "\n",
        "class GPTKerformerBlock(nn.Module):\n",
        "    def __init__(self, config: GPTKerformerConfig):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(config.n_embd, eps=1e-5)\n",
        "        self.attn = KerformerAttention(\n",
        "            embed_dim=config.n_embd,\n",
        "            num_heads=config.n_head,\n",
        "            dropout=config.attention_probs_dropout_prob,\n",
        "            causal=True,\n",
        "            degree=config.kerformer_degree,\n",
        "        )\n",
        "        self.ln_2 = nn.LayerNorm(config.n_embd, eps=1e-5)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(config.n_embd, 4 * config.n_embd),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(4 * config.n_embd, config.n_embd),\n",
        "            nn.Dropout(config.hidden_dropout_prob),\n",
        "        )\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None):\n",
        "        # Attention\n",
        "        residual = hidden_states\n",
        "        hidden_states = self.ln_1(hidden_states)\n",
        "        hidden_states = self.attn(hidden_states, attention_mask=attention_mask)\n",
        "        hidden_states = residual + hidden_states\n",
        "\n",
        "        # MLP\n",
        "        residual = hidden_states\n",
        "        hidden_states = self.ln_2(hidden_states)\n",
        "        hidden_states = self.mlp(hidden_states)\n",
        "        hidden_states = residual + hidden_states\n",
        "\n",
        "        return hidden_states"
      ],
      "metadata": {
        "id": "Ma_twvgfovuO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------\n",
        "# 4. Build the Complete GPT-Kerformer Model\n",
        "# -------------------------------------------\n",
        "\n",
        "class GPTKerformerModel(PreTrainedModel):\n",
        "    \"\"\"\n",
        "    A GPT-style language model using Kerformer attention.\n",
        "    \"\"\"\n",
        "\n",
        "    config_class = GPTKerformerConfig\n",
        "\n",
        "    def __init__(self, config: GPTKerformerConfig):\n",
        "        super().__init__(config)\n",
        "        self.embed_dim = config.n_embd\n",
        "\n",
        "        # Embeddings\n",
        "        self.wte = nn.Embedding(config.vocab_size, config.n_embd)  # token embeddings\n",
        "        self.wpe = nn.Embedding(config.max_position_embeddings, config.n_embd)  # positional embeddings\n",
        "        self.drop = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # Blocks\n",
        "        self.blocks = nn.ModuleList([GPTKerformerBlock(config) for _ in range(config.n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(config.n_embd, eps=1e-5)\n",
        "\n",
        "        # LM head\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "\n",
        "        self.post_init()  # from PreTrainedModel\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        labels=None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        \"\"\"\n",
        "        input_ids: [batch_size, seq_len]\n",
        "        attention_mask: [batch_size, seq_len]\n",
        "        labels: optional, [batch_size, seq_len]\n",
        "        \"\"\"\n",
        "        batch_size, seq_len = input_ids.shape\n",
        "        device = input_ids.device\n",
        "\n",
        "        position_ids = torch.arange(0, seq_len, dtype=torch.long, device=device)\n",
        "        position_ids = position_ids.unsqueeze(0).expand(batch_size, seq_len)\n",
        "\n",
        "        # Embed\n",
        "        inputs_embeds = self.wte(input_ids)\n",
        "        position_embeds = self.wpe(position_ids)\n",
        "        hidden_states = inputs_embeds + position_embeds\n",
        "        hidden_states = self.drop(hidden_states)\n",
        "\n",
        "        # Extended attention mask if we want to incorporate pad tokens, etc.\n",
        "        extended_mask = None\n",
        "        if attention_mask is not None:\n",
        "            extended_mask = attention_mask.unsqueeze(1).unsqueeze(2)  # [B, 1, 1, S]\n",
        "            extended_mask = (1.0 - extended_mask) * -1e4\n",
        "\n",
        "        # Pass through blocks\n",
        "        for block in self.blocks:\n",
        "            hidden_states = block(hidden_states, attention_mask=extended_mask)\n",
        "\n",
        "        # Final layer norm\n",
        "        hidden_states = self.ln_f(hidden_states)\n",
        "\n",
        "        # LM head\n",
        "        logits = self.lm_head(hidden_states)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            # Shift for next-token prediction\n",
        "            shift_logits = logits[:, :-1, :].contiguous()\n",
        "            shift_labels = labels[:, 1:].contiguous()\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(\n",
        "                shift_logits.view(-1, shift_logits.size(-1)),\n",
        "                shift_labels.view(-1)\n",
        "            )\n",
        "\n",
        "        return {\"loss\": loss, \"logits\": logits}"
      ],
      "metadata": {
        "id": "YhHCU2RgoxV-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------\n",
        "# 5. Data Loading: WikiText\n",
        "# -------------------------------------------\n",
        "\n",
        "def load_wikitext_dataset(dataset_name=\"wikitext\", dataset_version=\"wikitext-2-raw-v1\"):\n",
        "    # Returns a DatasetDict with 'train', 'validation', 'test' splits.\n",
        "    dataset = load_dataset(dataset_name, dataset_version)\n",
        "    return dataset\n",
        "\n",
        "# -------------------------------------------\n",
        "# 6. Tokenizer\n",
        "# -------------------------------------------\n",
        "\n",
        "def get_tokenizer(model_name=\"gpt2\"):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    # GPT-2 doesn't have an official pad token\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    return tokenizer"
      ],
      "metadata": {
        "id": "UK-qZV5NozCQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------\n",
        "# 7. Dataset Preprocessing\n",
        "# -------------------------------------------\n",
        "\n",
        "def preprocess_examples(examples, tokenizer, block_size=128):\n",
        "    \"\"\"\n",
        "    Tokenize the text examples, chunk them into blocks of size 'block_size'.\n",
        "    Returns a dict of tokenized examples (input_ids, etc.).\n",
        "    \"\"\"\n",
        "    text = examples[\"text\"]\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        add_special_tokens=False,\n",
        "        truncation=True,\n",
        "        max_length=block_size,\n",
        "        return_attention_mask=False\n",
        "    )\n",
        "    return encoding\n",
        "\n",
        "def group_texts(examples, block_size=128):\n",
        "    \"\"\"\n",
        "    Group the list of token ids into continuous chunks of size block_size.\n",
        "    \"\"\"\n",
        "    concatenated = []\n",
        "    for ids in examples[\"input_ids\"]:\n",
        "        concatenated.extend(ids)\n",
        "    result = []\n",
        "    for i in range(0, len(concatenated), block_size):\n",
        "        chunk = concatenated[i : i + block_size]\n",
        "        if len(chunk) == block_size:\n",
        "            result.append(chunk)\n",
        "    return {\"input_ids\": result}"
      ],
      "metadata": {
        "id": "TpnY5bxao1Dg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------\n",
        "# 8. Training\n",
        "# -------------------------------------------\n",
        "\n",
        "# 1) Load dataset\n",
        "raw_dataset = load_wikitext_dataset()\n",
        "\n",
        "# 2) Tokenizer\n",
        "tokenizer = get_tokenizer()\n",
        "\n",
        "# 3) Preprocess dataset\n",
        "block_size = 128\n",
        "def tokenize_function(examples):\n",
        "    return preprocess_examples(examples, tokenizer, block_size=block_size)\n",
        "tokenized_dataset = raw_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "# 4) Group texts\n",
        "def group_function(examples):\n",
        "    return group_texts(examples, block_size=block_size)\n",
        "lm_dataset = tokenized_dataset.map(group_function, batched=True)\n",
        "\n",
        "# 5) Data collator for LM\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "270ee667fb6b42e58084b4949110b31d",
            "0354a5a727f94aa59e4c84a16912fd7f",
            "1300055fd47a4f98b35e89a3d270e3c4",
            "4c7bdd4b5fba4068a8cef4a400214c14",
            "7511a81ca67f42f094b5308b81b8bde1",
            "6618ddf7a8e74f92a0a55454e6ed6ca6",
            "43b300ea48904320a7bbaa274aab3972",
            "9c3a64a305bd4c97aa2c06d9c7a45203",
            "dea4223d5a0b4837a4332a158f0e6690",
            "e5a1b7f3a1fa4b66be2d837c5fadeb94",
            "21868b83e1514e46bd064d61bc633646",
            "8c5d137051b14029a9f8ce605b8822a0",
            "65a8a2f723584f5cabdc4ddfe42da465",
            "6a69eef767eb4ccea29bc358582cc061",
            "0f31bb7e1c6b4adea81bfcf517f036b9",
            "eb391af1f3b44584b1f84b535bbbc02b",
            "2c6eaa8738044388aad7bf920bf5a66c",
            "35204ba9480f44eca77e7e33262f8d81",
            "6ca4783d8a9d44dc9a975f1010338aee",
            "2c1857891a16443498bd2aaed3e644b1",
            "f1035f7eb697464590597f3223b0fa9c",
            "7ab11b24f06440a298b2abd159156828"
          ]
        },
        "id": "mdzg63SRo6dF",
        "outputId": "50410a2e-b07a-4f71-cdab-34c21108d2a7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/36718 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "270ee667fb6b42e58084b4949110b31d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/36718 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c5d137051b14029a9f8ce605b8822a0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Create PyTorch Datasets & DataLoaders\n",
        "train_dataset = lm_dataset[\"train\"]\n",
        "val_dataset = lm_dataset[\"validation\"]\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=data_collator)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=False, collate_fn=data_collator)\n",
        "\n",
        "# 7) Initialize model and optimizer\n",
        "config = GPTKerformerConfig(\n",
        "    vocab_size=len(tokenizer),\n",
        "    max_position_embeddings=1024,\n",
        "    n_embd=256,\n",
        "    n_layer=4,\n",
        "    n_head=4,\n",
        "    hidden_dropout_prob=0.1,\n",
        "    attention_probs_dropout_prob=0.1,\n",
        "    kerformer_degree=2,\n",
        ")\n",
        "\n",
        "model = GPTKerformerModel(config)\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# We'll do a simple Adam optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "MbDiFurapZA1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import psutil\n",
        "import torch\n",
        "\n",
        "def print_memory_usage(stage=\"\"):\n",
        "    # Track GPU memory if available\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        gpu_alloc = torch.cuda.memory_allocated(device) / (1024 ** 2)\n",
        "        gpu_reserved = torch.cuda.memory_reserved(device) / (1024 ** 2)\n",
        "        print(f\"{stage} GPU Memory - Allocated: {gpu_alloc:.2f} MB, Reserved: {gpu_reserved:.2f} MB\")\n",
        "    # Track CPU memory usage for this process\n",
        "    process = psutil.Process(os.getpid())\n",
        "    cpu_usage = process.memory_info().rss / (1024 ** 2)\n",
        "    print(f\"{stage} CPU Memory Usage: {cpu_usage:.2f} MB\")"
      ],
      "metadata": {
        "id": "0Ja0nx8j6s0d"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "loss_vals = []\n",
        "val_loss_vals = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\n--- Epoch {epoch+1} ---\")\n",
        "    print_memory_usage(stage=\"Start of Epoch\")\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Move data to device\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device) if \"labels\" in batch else None\n",
        "        attention_mask = (input_ids != tokenizer.pad_token_id).long().to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs[\"loss\"]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_val = loss.item()\n",
        "        total_loss += loss_val\n",
        "\n",
        "        if (step + 1) % 100 == 0:\n",
        "            print(f\"Epoch {epoch+1} Step {step+1} - Loss: {loss_val:.4f}\")\n",
        "            print_memory_usage(stage=f\"After step {step+1}\")\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    loss_vals.append(avg_train_loss)\n",
        "    print(f\"Epoch {epoch+1} Training Loss: {avg_train_loss:.4f}\")\n",
        "    print_memory_usage(stage=\"End of Training Epoch\")\n",
        "\n",
        "    # Validation Loop\n",
        "    model.eval()\n",
        "    total_val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device) if \"labels\" in batch else None\n",
        "            attention_mask = (input_ids != tokenizer.pad_token_id).long().to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs[\"loss\"]\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "    val_loss_vals.append(avg_val_loss)\n",
        "    print(f\"Epoch {epoch+1} Validation Loss: {avg_val_loss:.4f}\")\n",
        "    print_memory_usage(stage=\"After Validation Epoch\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ApJRd4zIpgaS",
        "outputId": "94b73ff9-f5db-4476-9c76-8459566d6d48"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Epoch 1 ---\n",
            "Start of Epoch GPU Memory - Allocated: 405.41 MB, Reserved: 752.00 MB\n",
            "Start of Epoch CPU Memory Usage: 1844.72 MB\n",
            "Epoch 1 Step 100 - Loss: 8.6702\n",
            "After step 100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 100 CPU Memory Usage: 1844.72 MB\n",
            "Epoch 1 Step 200 - Loss: 7.6869\n",
            "After step 200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 300 - Loss: 7.7150\n",
            "After step 300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 400 - Loss: 7.6095\n",
            "After step 400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 500 - Loss: 7.8108\n",
            "After step 500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 600 - Loss: 7.2716\n",
            "After step 600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 700 - Loss: 7.4986\n",
            "After step 700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 800 - Loss: 7.2907\n",
            "After step 800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 900 - Loss: 6.8725\n",
            "After step 900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 1000 - Loss: 7.6069\n",
            "After step 1000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 1100 - Loss: 7.2970\n",
            "After step 1100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 1200 - Loss: 7.0988\n",
            "After step 1200 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 1200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 1300 - Loss: 7.0329\n",
            "After step 1300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 1400 - Loss: 6.1396\n",
            "After step 1400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 1500 - Loss: 7.4105\n",
            "After step 1500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 1600 - Loss: 7.0795\n",
            "After step 1600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 1700 - Loss: 7.2651\n",
            "After step 1700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 1800 - Loss: 6.9285\n",
            "After step 1800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 1900 - Loss: 7.1769\n",
            "After step 1900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 2000 - Loss: 6.9118\n",
            "After step 2000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 2100 - Loss: 6.7556\n",
            "After step 2100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 2200 - Loss: 6.6671\n",
            "After step 2200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 2300 - Loss: 6.7247\n",
            "After step 2300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 2400 - Loss: 6.9664\n",
            "After step 2400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 2500 - Loss: 7.7118\n",
            "After step 2500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 2600 - Loss: 6.7700\n",
            "After step 2600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 2700 - Loss: 7.1658\n",
            "After step 2700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 2800 - Loss: 7.4085\n",
            "After step 2800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 2900 - Loss: 7.3744\n",
            "After step 2900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 3000 - Loss: 7.0769\n",
            "After step 3000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 3100 - Loss: 7.2955\n",
            "After step 3100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 3200 - Loss: 7.4865\n",
            "After step 3200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 3300 - Loss: 6.6564\n",
            "After step 3300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 3400 - Loss: 6.5508\n",
            "After step 3400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 3500 - Loss: 7.0114\n",
            "After step 3500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 3600 - Loss: 6.5770\n",
            "After step 3600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 3700 - Loss: 7.2348\n",
            "After step 3700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 3800 - Loss: 6.6300\n",
            "After step 3800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 3900 - Loss: 7.1777\n",
            "After step 3900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 4000 - Loss: 7.2867\n",
            "After step 4000 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 4000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 4100 - Loss: 6.7527\n",
            "After step 4100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 4200 - Loss: 6.4829\n",
            "After step 4200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 4300 - Loss: 6.6593\n",
            "After step 4300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 4400 - Loss: 6.7662\n",
            "After step 4400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 4500 - Loss: 6.7934\n",
            "After step 4500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 4600 - Loss: 7.0772\n",
            "After step 4600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 4700 - Loss: 6.8128\n",
            "After step 4700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 4800 - Loss: 6.0124\n",
            "After step 4800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 4900 - Loss: 6.6286\n",
            "After step 4900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 5000 - Loss: 7.1402\n",
            "After step 5000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 5100 - Loss: 6.9088\n",
            "After step 5100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 5200 - Loss: 7.2228\n",
            "After step 5200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 5300 - Loss: 6.5928\n",
            "After step 5300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 5400 - Loss: 7.2104\n",
            "After step 5400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 5500 - Loss: 7.0078\n",
            "After step 5500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 5600 - Loss: 6.7761\n",
            "After step 5600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 5700 - Loss: 7.3147\n",
            "After step 5700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 5800 - Loss: 7.0600\n",
            "After step 5800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 5900 - Loss: 7.0353\n",
            "After step 5900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 6000 - Loss: 6.9130\n",
            "After step 6000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 6100 - Loss: 6.6707\n",
            "After step 6100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 6200 - Loss: 6.7376\n",
            "After step 6200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 6300 - Loss: 6.9467\n",
            "After step 6300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 6400 - Loss: 7.1517\n",
            "After step 6400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 6500 - Loss: 6.8950\n",
            "After step 6500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 6600 - Loss: 6.8676\n",
            "After step 6600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 6700 - Loss: 7.0555\n",
            "After step 6700 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 6700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Step 6800 - Loss: 6.9365\n",
            "After step 6800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Training Loss: 7.1564\n",
            "End of Training Epoch GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "End of Training Epoch CPU Memory Usage: 1848.74 MB\n",
            "Epoch 1 Validation Loss: 6.8920\n",
            "After Validation Epoch GPU Memory - Allocated: 543.01 MB, Reserved: 978.00 MB\n",
            "After Validation Epoch CPU Memory Usage: 1848.74 MB\n",
            "\n",
            "--- Epoch 2 ---\n",
            "Start of Epoch GPU Memory - Allocated: 543.01 MB, Reserved: 978.00 MB\n",
            "Start of Epoch CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 100 - Loss: 6.6194\n",
            "After step 100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 200 - Loss: 6.8006\n",
            "After step 200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 300 - Loss: 7.1553\n",
            "After step 300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 400 - Loss: 6.5083\n",
            "After step 400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 500 - Loss: 6.9423\n",
            "After step 500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 600 - Loss: 6.5308\n",
            "After step 600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 700 - Loss: 7.1927\n",
            "After step 700 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 800 - Loss: 6.6239\n",
            "After step 800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 900 - Loss: 6.9149\n",
            "After step 900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 1000 - Loss: 6.4811\n",
            "After step 1000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 1100 - Loss: 7.4180\n",
            "After step 1100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 1200 - Loss: 6.8188\n",
            "After step 1200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 1300 - Loss: 6.6489\n",
            "After step 1300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 1400 - Loss: 6.2873\n",
            "After step 1400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 1500 - Loss: 7.0216\n",
            "After step 1500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 1600 - Loss: 6.7031\n",
            "After step 1600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 1700 - Loss: 6.5534\n",
            "After step 1700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 1800 - Loss: 6.8826\n",
            "After step 1800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 1900 - Loss: 6.3335\n",
            "After step 1900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 2000 - Loss: 6.5922\n",
            "After step 2000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 2100 - Loss: 6.6573\n",
            "After step 2100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 2200 - Loss: 7.1635\n",
            "After step 2200 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 2200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 2300 - Loss: 6.2178\n",
            "After step 2300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 2400 - Loss: 5.7572\n",
            "After step 2400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 2500 - Loss: 6.8850\n",
            "After step 2500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 2600 - Loss: 6.7729\n",
            "After step 2600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 2700 - Loss: 6.7060\n",
            "After step 2700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 2800 - Loss: 6.7146\n",
            "After step 2800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 2900 - Loss: 6.7109\n",
            "After step 2900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 3000 - Loss: 6.6339\n",
            "After step 3000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 3100 - Loss: 6.5586\n",
            "After step 3100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 3200 - Loss: 6.4684\n",
            "After step 3200 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 3200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 3300 - Loss: 7.3411\n",
            "After step 3300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 3400 - Loss: 6.4797\n",
            "After step 3400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 3500 - Loss: 5.9972\n",
            "After step 3500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 3600 - Loss: 6.3216\n",
            "After step 3600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 3700 - Loss: 6.3027\n",
            "After step 3700 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 3700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 3800 - Loss: 6.6266\n",
            "After step 3800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 3900 - Loss: 6.3088\n",
            "After step 3900 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 3900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 4000 - Loss: 6.5155\n",
            "After step 4000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 4100 - Loss: 6.5947\n",
            "After step 4100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 4200 - Loss: 6.3463\n",
            "After step 4200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 4300 - Loss: 6.2383\n",
            "After step 4300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 4400 - Loss: 6.9398\n",
            "After step 4400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 4500 - Loss: 6.4883\n",
            "After step 4500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 4600 - Loss: 6.6167\n",
            "After step 4600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 4700 - Loss: 6.9338\n",
            "After step 4700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 4800 - Loss: 6.8565\n",
            "After step 4800 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 4800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 4900 - Loss: 6.1217\n",
            "After step 4900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 5000 - Loss: 6.3505\n",
            "After step 5000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 5100 - Loss: 7.1508\n",
            "After step 5100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 5200 - Loss: 6.5664\n",
            "After step 5200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 5300 - Loss: 6.4870\n",
            "After step 5300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 5400 - Loss: 6.3059\n",
            "After step 5400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 5500 - Loss: 7.0065\n",
            "After step 5500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 5600 - Loss: 6.4115\n",
            "After step 5600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 5700 - Loss: 5.7803\n",
            "After step 5700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 5800 - Loss: 5.8054\n",
            "After step 5800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 5900 - Loss: 6.3222\n",
            "After step 5900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 6000 - Loss: 6.5282\n",
            "After step 6000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 6100 - Loss: 6.4275\n",
            "After step 6100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 6200 - Loss: 6.4782\n",
            "After step 6200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 6300 - Loss: 6.0736\n",
            "After step 6300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 6400 - Loss: 5.8782\n",
            "After step 6400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 6500 - Loss: 6.4335\n",
            "After step 6500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 6600 - Loss: 5.8510\n",
            "After step 6600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 6700 - Loss: 6.5194\n",
            "After step 6700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Step 6800 - Loss: 6.4304\n",
            "After step 6800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Training Loss: 6.5323\n",
            "End of Training Epoch GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "End of Training Epoch CPU Memory Usage: 1848.74 MB\n",
            "Epoch 2 Validation Loss: 6.5697\n",
            "After Validation Epoch GPU Memory - Allocated: 543.01 MB, Reserved: 978.00 MB\n",
            "After Validation Epoch CPU Memory Usage: 1848.74 MB\n",
            "\n",
            "--- Epoch 3 ---\n",
            "Start of Epoch GPU Memory - Allocated: 543.01 MB, Reserved: 978.00 MB\n",
            "Start of Epoch CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 100 - Loss: 6.1889\n",
            "After step 100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 200 - Loss: 5.7209\n",
            "After step 200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 300 - Loss: 6.4257\n",
            "After step 300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 400 - Loss: 6.1963\n",
            "After step 400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 500 - Loss: 6.5025\n",
            "After step 500 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 600 - Loss: 6.2110\n",
            "After step 600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 700 - Loss: 6.4963\n",
            "After step 700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 800 - Loss: 6.1013\n",
            "After step 800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 900 - Loss: 5.8239\n",
            "After step 900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 1000 - Loss: 6.1143\n",
            "After step 1000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 1100 - Loss: 5.9926\n",
            "After step 1100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 1200 - Loss: 5.8093\n",
            "After step 1200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 1300 - Loss: 5.7448\n",
            "After step 1300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 1400 - Loss: 5.4432\n",
            "After step 1400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 1500 - Loss: 6.5093\n",
            "After step 1500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 1600 - Loss: 6.1688\n",
            "After step 1600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 1700 - Loss: 5.8605\n",
            "After step 1700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 1800 - Loss: 6.4104\n",
            "After step 1800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 1900 - Loss: 5.8173\n",
            "After step 1900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 2000 - Loss: 6.5289\n",
            "After step 2000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 2100 - Loss: 5.2232\n",
            "After step 2100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 2200 - Loss: 5.8039\n",
            "After step 2200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 2300 - Loss: 5.7659\n",
            "After step 2300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 2400 - Loss: 6.5574\n",
            "After step 2400 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 2400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 2500 - Loss: 5.6703\n",
            "After step 2500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 2600 - Loss: 6.1380\n",
            "After step 2600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 2700 - Loss: 6.0568\n",
            "After step 2700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 2800 - Loss: 5.8152\n",
            "After step 2800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 2900 - Loss: 6.1076\n",
            "After step 2900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 3000 - Loss: 6.1502\n",
            "After step 3000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 3100 - Loss: 5.7788\n",
            "After step 3100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 3200 - Loss: 6.1959\n",
            "After step 3200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 3300 - Loss: 5.6964\n",
            "After step 3300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 3400 - Loss: 5.5013\n",
            "After step 3400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 3500 - Loss: 5.9343\n",
            "After step 3500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 3600 - Loss: 5.5380\n",
            "After step 3600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 3700 - Loss: 5.5830\n",
            "After step 3700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 3800 - Loss: 6.0935\n",
            "After step 3800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 3900 - Loss: 5.9888\n",
            "After step 3900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 4000 - Loss: 5.6295\n",
            "After step 4000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 4100 - Loss: 5.7301\n",
            "After step 4100 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 4100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 4200 - Loss: 6.5365\n",
            "After step 4200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 4300 - Loss: 5.6269\n",
            "After step 4300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 4400 - Loss: 6.1915\n",
            "After step 4400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 4500 - Loss: 5.8967\n",
            "After step 4500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 4600 - Loss: 6.4063\n",
            "After step 4600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 4700 - Loss: 5.6260\n",
            "After step 4700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 4800 - Loss: 4.8062\n",
            "After step 4800 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 4800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 4900 - Loss: 5.7951\n",
            "After step 4900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 5000 - Loss: 6.1933\n",
            "After step 5000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 5100 - Loss: 5.4717\n",
            "After step 5100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 5200 - Loss: 5.8001\n",
            "After step 5200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 5300 - Loss: 5.6017\n",
            "After step 5300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 5400 - Loss: 5.7031\n",
            "After step 5400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 5500 - Loss: 6.0184\n",
            "After step 5500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 5600 - Loss: 6.0287\n",
            "After step 5600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 5700 - Loss: 6.0850\n",
            "After step 5700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 5800 - Loss: 6.0494\n",
            "After step 5800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 5900 - Loss: 5.7685\n",
            "After step 5900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 6000 - Loss: 5.1821\n",
            "After step 6000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 6100 - Loss: 5.9273\n",
            "After step 6100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 6200 - Loss: 6.0111\n",
            "After step 6200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 6300 - Loss: 5.6456\n",
            "After step 6300 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 6300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 6400 - Loss: 5.8772\n",
            "After step 6400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 6500 - Loss: 5.9643\n",
            "After step 6500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 6600 - Loss: 5.9884\n",
            "After step 6600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 6700 - Loss: 5.4753\n",
            "After step 6700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Step 6800 - Loss: 5.5255\n",
            "After step 6800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Training Loss: 5.9949\n",
            "End of Training Epoch GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "End of Training Epoch CPU Memory Usage: 1848.74 MB\n",
            "Epoch 3 Validation Loss: 6.3666\n",
            "After Validation Epoch GPU Memory - Allocated: 543.01 MB, Reserved: 978.00 MB\n",
            "After Validation Epoch CPU Memory Usage: 1848.74 MB\n",
            "\n",
            "--- Epoch 4 ---\n",
            "Start of Epoch GPU Memory - Allocated: 543.01 MB, Reserved: 978.00 MB\n",
            "Start of Epoch CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 100 - Loss: 6.1288\n",
            "After step 100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 200 - Loss: 6.1204\n",
            "After step 200 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 300 - Loss: 6.1619\n",
            "After step 300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 400 - Loss: 5.8727\n",
            "After step 400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 500 - Loss: 5.3057\n",
            "After step 500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 600 - Loss: 5.6307\n",
            "After step 600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 700 - Loss: 5.6033\n",
            "After step 700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 800 - Loss: 5.2389\n",
            "After step 800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 900 - Loss: 5.8559\n",
            "After step 900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 1000 - Loss: 6.0441\n",
            "After step 1000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 1100 - Loss: 5.4255\n",
            "After step 1100 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 1100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 1200 - Loss: 5.2807\n",
            "After step 1200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 1300 - Loss: 5.4832\n",
            "After step 1300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 1400 - Loss: 5.2420\n",
            "After step 1400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 1500 - Loss: 5.4921\n",
            "After step 1500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 1600 - Loss: 5.7086\n",
            "After step 1600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 1700 - Loss: 5.1605\n",
            "After step 1700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 1800 - Loss: 5.4479\n",
            "After step 1800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 1900 - Loss: 5.1250\n",
            "After step 1900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 2000 - Loss: 5.5906\n",
            "After step 2000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 2100 - Loss: 5.6462\n",
            "After step 2100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 2200 - Loss: 5.2863\n",
            "After step 2200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 2300 - Loss: 5.3451\n",
            "After step 2300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 2400 - Loss: 4.8394\n",
            "After step 2400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 2500 - Loss: 5.5136\n",
            "After step 2500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 2600 - Loss: 6.0195\n",
            "After step 2600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 2700 - Loss: 5.8150\n",
            "After step 2700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 2800 - Loss: 5.5132\n",
            "After step 2800 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 2800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 2900 - Loss: 5.7288\n",
            "After step 2900 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 2900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 3000 - Loss: 5.4424\n",
            "After step 3000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 3100 - Loss: 5.2713\n",
            "After step 3100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 3200 - Loss: 5.5252\n",
            "After step 3200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 3300 - Loss: 5.3922\n",
            "After step 3300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 3400 - Loss: 5.5468\n",
            "After step 3400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 3500 - Loss: 4.7238\n",
            "After step 3500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 3600 - Loss: 5.1885\n",
            "After step 3600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 3700 - Loss: 5.1263\n",
            "After step 3700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 3800 - Loss: 4.7391\n",
            "After step 3800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 3900 - Loss: 5.4917\n",
            "After step 3900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 4000 - Loss: 5.6871\n",
            "After step 4000 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 4000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 4100 - Loss: 5.1129\n",
            "After step 4100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 4200 - Loss: 5.2236\n",
            "After step 4200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 4300 - Loss: 5.1689\n",
            "After step 4300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 4400 - Loss: 5.0484\n",
            "After step 4400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 4500 - Loss: 5.1985\n",
            "After step 4500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 4600 - Loss: 4.9626\n",
            "After step 4600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 4700 - Loss: 5.2240\n",
            "After step 4700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 4800 - Loss: 4.9171\n",
            "After step 4800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 4900 - Loss: 5.0950\n",
            "After step 4900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 5000 - Loss: 4.4878\n",
            "After step 5000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 5100 - Loss: 4.8727\n",
            "After step 5100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 5200 - Loss: 4.3377\n",
            "After step 5200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 5300 - Loss: 4.8500\n",
            "After step 5300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 5400 - Loss: 5.1356\n",
            "After step 5400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 5500 - Loss: 3.9366\n",
            "After step 5500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 5600 - Loss: 4.8591\n",
            "After step 5600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 5700 - Loss: 4.8524\n",
            "After step 5700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 5800 - Loss: 4.8549\n",
            "After step 5800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 5900 - Loss: 5.5799\n",
            "After step 5900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 6000 - Loss: 4.4720\n",
            "After step 6000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 6100 - Loss: 4.2761\n",
            "After step 6100 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 6100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 6200 - Loss: 5.0010\n",
            "After step 6200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 6300 - Loss: 3.8393\n",
            "After step 6300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 6400 - Loss: 4.5700\n",
            "After step 6400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 6500 - Loss: 3.9944\n",
            "After step 6500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 6600 - Loss: 4.0738\n",
            "After step 6600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 6700 - Loss: 4.4106\n",
            "After step 6700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Step 6800 - Loss: 4.2712\n",
            "After step 6800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Training Loss: 5.1152\n",
            "End of Training Epoch GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "End of Training Epoch CPU Memory Usage: 1848.74 MB\n",
            "Epoch 4 Validation Loss: 4.4627\n",
            "After Validation Epoch GPU Memory - Allocated: 543.01 MB, Reserved: 978.00 MB\n",
            "After Validation Epoch CPU Memory Usage: 1848.74 MB\n",
            "\n",
            "--- Epoch 5 ---\n",
            "Start of Epoch GPU Memory - Allocated: 543.01 MB, Reserved: 978.00 MB\n",
            "Start of Epoch CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 100 - Loss: 3.5809\n",
            "After step 100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 200 - Loss: 3.9524\n",
            "After step 200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 300 - Loss: 3.1479\n",
            "After step 300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 400 - Loss: 3.6090\n",
            "After step 400 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 500 - Loss: 3.7136\n",
            "After step 500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 600 - Loss: 3.1415\n",
            "After step 600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 700 - Loss: 3.3124\n",
            "After step 700 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 800 - Loss: 3.5637\n",
            "After step 800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 900 - Loss: 3.4336\n",
            "After step 900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 1000 - Loss: 3.4527\n",
            "After step 1000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 1100 - Loss: 3.3454\n",
            "After step 1100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 1200 - Loss: 2.9742\n",
            "After step 1200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 1300 - Loss: 3.5923\n",
            "After step 1300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 1400 - Loss: 2.7652\n",
            "After step 1400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 1500 - Loss: 2.7181\n",
            "After step 1500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 1600 - Loss: 3.1393\n",
            "After step 1600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 1700 - Loss: 3.1197\n",
            "After step 1700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 1800 - Loss: 2.6077\n",
            "After step 1800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 1900 - Loss: 3.4417\n",
            "After step 1900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 2000 - Loss: 3.4427\n",
            "After step 2000 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 2000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 2100 - Loss: 3.3759\n",
            "After step 2100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 2200 - Loss: 3.1904\n",
            "After step 2200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 2300 - Loss: 3.1469\n",
            "After step 2300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 2400 - Loss: 2.4284\n",
            "After step 2400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 2500 - Loss: 2.8159\n",
            "After step 2500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 2600 - Loss: 3.0092\n",
            "After step 2600 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 2600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 2700 - Loss: 2.9340\n",
            "After step 2700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 2800 - Loss: 2.7752\n",
            "After step 2800 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 2800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 2900 - Loss: 2.5740\n",
            "After step 2900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 3000 - Loss: 2.6588\n",
            "After step 3000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 3100 - Loss: 2.7484\n",
            "After step 3100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 3200 - Loss: 2.6005\n",
            "After step 3200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 3300 - Loss: 2.6375\n",
            "After step 3300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 3400 - Loss: 1.6958\n",
            "After step 3400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 3500 - Loss: 2.3147\n",
            "After step 3500 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 3500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 3600 - Loss: 1.9682\n",
            "After step 3600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 3700 - Loss: 2.1764\n",
            "After step 3700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 3800 - Loss: 2.2193\n",
            "After step 3800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 3900 - Loss: 2.4808\n",
            "After step 3900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 4000 - Loss: 2.5927\n",
            "After step 4000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 4100 - Loss: 2.0271\n",
            "After step 4100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 4200 - Loss: 2.5899\n",
            "After step 4200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 4300 - Loss: 2.8298\n",
            "After step 4300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 4400 - Loss: 2.0890\n",
            "After step 4400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 4500 - Loss: 1.7079\n",
            "After step 4500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 4600 - Loss: 2.1711\n",
            "After step 4600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 4700 - Loss: 1.8075\n",
            "After step 4700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 4800 - Loss: 2.4625\n",
            "After step 4800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 4900 - Loss: 2.0620\n",
            "After step 4900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 5000 - Loss: 1.9966\n",
            "After step 5000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 5100 - Loss: 2.0879\n",
            "After step 5100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 5200 - Loss: 2.1934\n",
            "After step 5200 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 5200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 5300 - Loss: 2.0833\n",
            "After step 5300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 5400 - Loss: 1.9816\n",
            "After step 5400 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 5400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 5500 - Loss: 1.8264\n",
            "After step 5500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 5600 - Loss: 2.4416\n",
            "After step 5600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 5700 - Loss: 1.9692\n",
            "After step 5700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 5800 - Loss: 1.9624\n",
            "After step 5800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 5900 - Loss: 2.0327\n",
            "After step 5900 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 5900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 6000 - Loss: 1.9032\n",
            "After step 6000 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 6000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 6100 - Loss: 3.0735\n",
            "After step 6100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 6200 - Loss: 1.9968\n",
            "After step 6200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 6300 - Loss: 1.8196\n",
            "After step 6300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 6400 - Loss: 1.5749\n",
            "After step 6400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 6500 - Loss: 1.7184\n",
            "After step 6500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 6600 - Loss: 1.9707\n",
            "After step 6600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 6700 - Loss: 2.1281\n",
            "After step 6700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Step 6800 - Loss: 1.6211\n",
            "After step 6800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Training Loss: 2.6292\n",
            "End of Training Epoch GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "End of Training Epoch CPU Memory Usage: 1848.74 MB\n",
            "Epoch 5 Validation Loss: 2.1611\n",
            "After Validation Epoch GPU Memory - Allocated: 543.01 MB, Reserved: 978.00 MB\n",
            "After Validation Epoch CPU Memory Usage: 1848.74 MB\n",
            "\n",
            "--- Epoch 6 ---\n",
            "Start of Epoch GPU Memory - Allocated: 543.01 MB, Reserved: 978.00 MB\n",
            "Start of Epoch CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 100 - Loss: 2.2682\n",
            "After step 100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 200 - Loss: 1.5433\n",
            "After step 200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 300 - Loss: 1.8794\n",
            "After step 300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 400 - Loss: 2.1027\n",
            "After step 400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 500 - Loss: 2.8809\n",
            "After step 500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 600 - Loss: 2.9011\n",
            "After step 600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 700 - Loss: 4.2340\n",
            "After step 700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 800 - Loss: 3.8794\n",
            "After step 800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 900 - Loss: 6.4781\n",
            "After step 900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 1000 - Loss: 5.4455\n",
            "After step 1000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 1100 - Loss: 5.7985\n",
            "After step 1100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 1200 - Loss: 4.9867\n",
            "After step 1200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 1300 - Loss: 6.2747\n",
            "After step 1300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 1400 - Loss: 6.1380\n",
            "After step 1400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 1500 - Loss: 6.5445\n",
            "After step 1500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 1600 - Loss: 5.9484\n",
            "After step 1600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 1700 - Loss: 6.1150\n",
            "After step 1700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 1800 - Loss: 6.0452\n",
            "After step 1800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 1900 - Loss: 4.9605\n",
            "After step 1900 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 1900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 2000 - Loss: 5.9106\n",
            "After step 2000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 2100 - Loss: 5.8889\n",
            "After step 2100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 2200 - Loss: 6.0273\n",
            "After step 2200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 2300 - Loss: 6.1816\n",
            "After step 2300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 2400 - Loss: 6.4299\n",
            "After step 2400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 2500 - Loss: 4.9764\n",
            "After step 2500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 2600 - Loss: 5.4985\n",
            "After step 2600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 2700 - Loss: 5.1528\n",
            "After step 2700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 2800 - Loss: 6.0589\n",
            "After step 2800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 2900 - Loss: 5.8592\n",
            "After step 2900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 3000 - Loss: 6.0073\n",
            "After step 3000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 3100 - Loss: 6.0728\n",
            "After step 3100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 3200 - Loss: 5.4326\n",
            "After step 3200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 3300 - Loss: 5.6057\n",
            "After step 3300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 3400 - Loss: 5.3160\n",
            "After step 3400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 3500 - Loss: 5.5970\n",
            "After step 3500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 3600 - Loss: 6.4531\n",
            "After step 3600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 3700 - Loss: 6.0574\n",
            "After step 3700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 3800 - Loss: 5.2312\n",
            "After step 3800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 3900 - Loss: 6.2496\n",
            "After step 3900 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 3900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 4000 - Loss: 5.5182\n",
            "After step 4000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 4100 - Loss: 5.8020\n",
            "After step 4100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 4200 - Loss: 4.9620\n",
            "After step 4200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 4300 - Loss: 5.7199\n",
            "After step 4300 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 4300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 4400 - Loss: 5.4197\n",
            "After step 4400 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 4400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 4500 - Loss: 5.2717\n",
            "After step 4500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 4600 - Loss: 6.4741\n",
            "After step 4600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 4700 - Loss: 6.6562\n",
            "After step 4700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 4800 - Loss: 6.0982\n",
            "After step 4800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 4900 - Loss: 5.8650\n",
            "After step 4900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 5000 - Loss: 5.9223\n",
            "After step 5000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 5100 - Loss: 6.2937\n",
            "After step 5100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 5200 - Loss: 5.8994\n",
            "After step 5200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 5300 - Loss: 5.9316\n",
            "After step 5300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 5400 - Loss: 5.8529\n",
            "After step 5400 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 5400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 5500 - Loss: 7.4905\n",
            "After step 5500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 5600 - Loss: 6.3712\n",
            "After step 5600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 5700 - Loss: 6.2987\n",
            "After step 5700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 5800 - Loss: 6.4200\n",
            "After step 5800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 5900 - Loss: 6.0552\n",
            "After step 5900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5900 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 6000 - Loss: 6.0903\n",
            "After step 6000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6000 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 6100 - Loss: 5.9202\n",
            "After step 6100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 6200 - Loss: 6.2637\n",
            "After step 6200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 6300 - Loss: 5.7797\n",
            "After step 6300 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 6300 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 6400 - Loss: 6.1790\n",
            "After step 6400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6400 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 6500 - Loss: 5.9586\n",
            "After step 6500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6500 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 6600 - Loss: 6.1959\n",
            "After step 6600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6600 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 6700 - Loss: 6.0785\n",
            "After step 6700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6700 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Step 6800 - Loss: 5.8450\n",
            "After step 6800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6800 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Training Loss: 5.5148\n",
            "End of Training Epoch GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "End of Training Epoch CPU Memory Usage: 1848.74 MB\n",
            "Epoch 6 Validation Loss: 6.4368\n",
            "After Validation Epoch GPU Memory - Allocated: 543.01 MB, Reserved: 978.00 MB\n",
            "After Validation Epoch CPU Memory Usage: 1848.74 MB\n",
            "\n",
            "--- Epoch 7 ---\n",
            "Start of Epoch GPU Memory - Allocated: 543.01 MB, Reserved: 978.00 MB\n",
            "Start of Epoch CPU Memory Usage: 1848.74 MB\n",
            "Epoch 7 Step 100 - Loss: 5.6054\n",
            "After step 100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 100 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 7 Step 200 - Loss: 4.6962\n",
            "After step 200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 200 CPU Memory Usage: 1848.74 MB\n",
            "Epoch 7 Step 300 - Loss: 5.7203\n",
            "After step 300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 300 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 400 - Loss: 4.6240\n",
            "After step 400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 400 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 500 - Loss: 5.7994\n",
            "After step 500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 500 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 600 - Loss: 4.7482\n",
            "After step 600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 600 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 700 - Loss: 5.5231\n",
            "After step 700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 700 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 800 - Loss: 5.5818\n",
            "After step 800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 800 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 900 - Loss: 5.6608\n",
            "After step 900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 900 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 1000 - Loss: 5.1146\n",
            "After step 1000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1000 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 1100 - Loss: 5.5868\n",
            "After step 1100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1100 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 1200 - Loss: 5.4878\n",
            "After step 1200 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 1200 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 1300 - Loss: 5.6612\n",
            "After step 1300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1300 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 1400 - Loss: 5.2772\n",
            "After step 1400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1400 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 1500 - Loss: 4.7560\n",
            "After step 1500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1500 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 1600 - Loss: 5.7664\n",
            "After step 1600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1600 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 1700 - Loss: 5.3359\n",
            "After step 1700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1700 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 1800 - Loss: 5.5416\n",
            "After step 1800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1800 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 1900 - Loss: 6.3152\n",
            "After step 1900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 1900 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 2000 - Loss: 6.4983\n",
            "After step 2000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2000 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 2100 - Loss: 6.4817\n",
            "After step 2100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2100 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 2200 - Loss: 5.5785\n",
            "After step 2200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2200 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 2300 - Loss: 6.4653\n",
            "After step 2300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2300 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 2400 - Loss: 6.5094\n",
            "After step 2400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2400 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 2500 - Loss: 6.2176\n",
            "After step 2500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2500 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 2600 - Loss: 6.2018\n",
            "After step 2600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2600 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 2700 - Loss: 6.3238\n",
            "After step 2700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2700 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 2800 - Loss: 5.3756\n",
            "After step 2800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2800 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 2900 - Loss: 6.4478\n",
            "After step 2900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 2900 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 3000 - Loss: 6.6376\n",
            "After step 3000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3000 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 3100 - Loss: 6.0500\n",
            "After step 3100 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 3100 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 3200 - Loss: 6.2341\n",
            "After step 3200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3200 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 3300 - Loss: 5.8310\n",
            "After step 3300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3300 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 3400 - Loss: 5.9523\n",
            "After step 3400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3400 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 3500 - Loss: 6.0205\n",
            "After step 3500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3500 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 3600 - Loss: 6.5884\n",
            "After step 3600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3600 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 3700 - Loss: 5.7377\n",
            "After step 3700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3700 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 3800 - Loss: 5.7365\n",
            "After step 3800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3800 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 3900 - Loss: 6.1071\n",
            "After step 3900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 3900 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 4000 - Loss: 6.1707\n",
            "After step 4000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4000 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 4100 - Loss: 5.9721\n",
            "After step 4100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4100 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 4200 - Loss: 5.9700\n",
            "After step 4200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4200 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 4300 - Loss: 5.6235\n",
            "After step 4300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4300 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 4400 - Loss: 5.6008\n",
            "After step 4400 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 4400 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 4500 - Loss: 5.1701\n",
            "After step 4500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4500 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 4600 - Loss: 5.2464\n",
            "After step 4600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4600 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 4700 - Loss: 5.7114\n",
            "After step 4700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4700 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 4800 - Loss: 5.5281\n",
            "After step 4800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4800 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 4900 - Loss: 5.3177\n",
            "After step 4900 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 4900 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 5000 - Loss: 5.2652\n",
            "After step 5000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5000 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 5100 - Loss: 4.9633\n",
            "After step 5100 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 5100 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 5200 - Loss: 6.1060\n",
            "After step 5200 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5200 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 5300 - Loss: 5.2086\n",
            "After step 5300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5300 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 5400 - Loss: 6.0693\n",
            "After step 5400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5400 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 5500 - Loss: 6.1839\n",
            "After step 5500 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5500 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 5600 - Loss: 6.1990\n",
            "After step 5600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5600 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 5700 - Loss: 6.3593\n",
            "After step 5700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5700 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 5800 - Loss: 6.3436\n",
            "After step 5800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 5800 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 5900 - Loss: 5.6474\n",
            "After step 5900 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 5900 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 6000 - Loss: 6.1643\n",
            "After step 6000 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6000 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 6100 - Loss: 5.8477\n",
            "After step 6100 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6100 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 6200 - Loss: 6.0692\n",
            "After step 6200 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 6200 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 6300 - Loss: 5.5597\n",
            "After step 6300 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6300 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 6400 - Loss: 6.2029\n",
            "After step 6400 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6400 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 6500 - Loss: 6.1878\n",
            "After step 6500 GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "After step 6500 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 6600 - Loss: 6.2191\n",
            "After step 6600 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6600 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 6700 - Loss: 6.1637\n",
            "After step 6700 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6700 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Step 6800 - Loss: 5.9614\n",
            "After step 6800 GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "After step 6800 CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Training Loss: 5.8960\n",
            "End of Training Epoch GPU Memory - Allocated: 568.47 MB, Reserved: 978.00 MB\n",
            "End of Training Epoch CPU Memory Usage: 1849.00 MB\n",
            "Epoch 7 Validation Loss: 6.5300\n",
            "After Validation Epoch GPU Memory - Allocated: 543.01 MB, Reserved: 978.00 MB\n",
            "After Validation Epoch CPU Memory Usage: 1849.00 MB\n",
            "\n",
            "--- Epoch 8 ---\n",
            "Start of Epoch GPU Memory - Allocated: 543.01 MB, Reserved: 978.00 MB\n",
            "Start of Epoch CPU Memory Usage: 1849.00 MB\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-8d0c50c3c873>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = list(range(1, len(loss_vals) + 1))\n",
        "\n",
        "# Plot training loss\n",
        "plt.plot(epochs, loss_vals, label=\"Train Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss per Epoch\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "hElxAzP1xp1x",
        "outputId": "9e1313fe-7e99-4265-ed85-201a6af502fb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = list(range(1, len(val_loss_vals) + 1))\n",
        "\n",
        "plt.plot(epochs, val_loss_vals, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Validation Loss per Epoch\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ly4kkoqVyOzo",
        "outputId": "da98e160-0c0b-4a0c-aa0a-686f95530e89"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = \"Artificial intelligence is\"\n",
        "inputs = tokenizer.encode(test_text, return_tensors=\"pt\").to(device)\n",
        "model.eval()\n",
        "\n",
        "print_memory_usage(stage=\"Before Inference\")\n",
        "\n",
        "max_new_tokens = 50\n",
        "with torch.no_grad():\n",
        "    for _ in range(max_new_tokens):\n",
        "        outputs = model(inputs)\n",
        "        logits = outputs[\"logits\"]\n",
        "        # Greedy decoding: take the argmax of the last token's logits\n",
        "        next_token_id = torch.argmax(logits[0, -1, :])\n",
        "        inputs = torch.cat([inputs, next_token_id.unsqueeze(0).unsqueeze(0)], dim=1)\n",
        "\n",
        "generated_text = tokenizer.decode(inputs[0])\n",
        "print(f\"\\nPrompt: {test_text}\")\n",
        "print(f\"Generated text: {generated_text}\")\n",
        "\n",
        "print_memory_usage(stage=\"After Inference\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoSAIL6pu56m",
        "outputId": "91bc694d-9645-419c-c56f-007f8303a8cd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Inference GPU Memory - Allocated: 518.47 MB, Reserved: 978.00 MB\n",
            "Before Inference CPU Memory Usage: 1859.33 MB\n",
            "\n",
            "Prompt: Artificial intelligence is\n",
            "Generated text: Artificial intelligence is a \" , and the first game , and the same , and the first time , and the first broadcast , and the first of the first , and the first time , and the first time , and the first two , and the first time , the\n",
            "After Inference GPU Memory - Allocated: 482.27 MB, Reserved: 978.00 MB\n",
            "After Inference CPU Memory Usage: 1860.16 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = \"Artificial intelligence is\"\n",
        "inputs = tokenizer.encode(test_text, return_tensors=\"pt\").to(device)\n",
        "model.eval()\n",
        "\n",
        "print_memory_usage(stage=\"Before Inference\")\n",
        "\n",
        "max_new_tokens = 1000\n",
        "with torch.no_grad():\n",
        "    for _ in range(max_new_tokens):\n",
        "        outputs = model(inputs)\n",
        "        logits = outputs[\"logits\"]\n",
        "        # Greedy decoding: take the argmax of the last token's logits\n",
        "        next_token_id = torch.argmax(logits[0, -1, :])\n",
        "        inputs = torch.cat([inputs, next_token_id.unsqueeze(0).unsqueeze(0)], dim=1)\n",
        "\n",
        "generated_text = tokenizer.decode(inputs[0])\n",
        "print(f\"\\nPrompt: {test_text}\")\n",
        "print(f\"Generated text: {generated_text}\")\n",
        "\n",
        "print_memory_usage(stage=\"After Inference\")"
      ],
      "metadata": {
        "id": "88iJT8fN0FGL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b7af605-ffc5-402d-81da-6b3135a8f8ab"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Inference GPU Memory - Allocated: 478.63 MB, Reserved: 978.00 MB\n",
            "Before Inference CPU Memory Usage: 1860.16 MB\n",
            "\n",
            "Prompt: Artificial intelligence is\n",
            "Generated text: Artificial intelligence is a \" , and the first game , and the same , and the first time , and the first broadcast , and the first of the first , and the first time , and the first time , and the first two , and the first time , the first season , and the first time , and the first time , and the first , and the first time , and the first time , the first , the first time , the first time , the first , the first time , the first time , the first time , the first time , the first time , the first time , the first time , the first , the first , the first , the first , the first , the first , the first , the first , the first , the first , the first the first , the first the first , the first , the first , the first , the first , the first , the first , the first , the first , the first , the first , the first , the first , the first , the east , the , the , the , the first , the , the east , the east , the German , the first , the , the the the , the , the , the the , the , the , the , the , the , the the , the , the , the , the , the , the the the , the the , the the the , the , the , the the the the , the the the , the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the Brigade the Brigade the Brigade the Brigade the the Brigade the the the Brigade the Brigade the Brigade the Brigade Brigade the Brigade the Brigade the Brigade Brigade the Brigade the Brigade the Brigade the Brigade Brigade Brigade Brigade Brigade the Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade Brigade\n",
            "After Inference GPU Memory - Allocated: 660.77 MB, Reserved: 7154.00 MB\n",
            "After Inference CPU Memory Usage: 1860.16 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset)"
      ],
      "metadata": {
        "id": "RDMWZwk-_mBy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}